{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NER Model"
      ],
      "metadata": {
        "id": "vU21WdLgKPb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdzD480rKGGm"
      },
      "outputs": [],
      "source": [
        "# Импортирование модулей сервиса\n",
        "from ConversationManager import ConversationManager\n",
        "from NLU_classifier      import NLU_Classifier\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import pipeline, AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "class NerExtractor:\n",
        "    \"\"\"\n",
        "    Класс для извлечения именованных сущностей (NER) из текста, использующий предобученные модели из библиотеки transformers.\n",
        "\n",
        "    Атрибуты:\n",
        "        token_pred_pipeline (pipeline): Пайплайн для классификации токенов, используемый для извлечения сущностей.\n",
        "\n",
        "    Методы:\n",
        "        concat_entities: Объединяет именованные сущности, принадлежащие к одному и тому же типу и расположенные рядом друг с другом.\n",
        "        get_entities: Извлекает именованные сущности из предоставленного текста.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_checkpoint=\"./LaBSE_ner_nerel\"):\n",
        "        \"\"\"\n",
        "        Инициализирует экстрактор сущностей с использованием указанной модели.\n",
        "\n",
        "        Параметры:\n",
        "            model_checkpoint (str): Путь к предобученной модели NER.\n",
        "        \"\"\"\n",
        "        print('Loading NER model...')\n",
        "        # Загрузка токенизатора для предварительно обученной модели NER\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "        # Загрузка предварительно обученной модели NER с переносом на GPU для ускорения обработки\n",
        "        self.model = AutoModel.from_pretrained(model_checkpoint).to(device='cuda')\n",
        "        print('Retriver NER Loaded')\n",
        "\n",
        "        # Инициализация пайплайна для классификации токенов\n",
        "        self.token_pred_pipeline = pipeline(\"token-classification\",\n",
        "                                            model=self.model,\n",
        "                                            tokenizer=self.tokenizer,\n",
        "                                            aggregation_strategy=\"average\",\n",
        "                                            device='cuda')\n",
        "\n",
        "    @staticmethod\n",
        "    def concat_entities(ner_result):\n",
        "        \"\"\"\n",
        "        Объединяет последовательные именованные сущности одного типа в одну сущность.\n",
        "\n",
        "        Эта функция полезна для ситуаций, когда одна именованная сущность\n",
        "        разделена на несколько частей моделью NER. Например, \"Нью\" и \"Йорк\"\n",
        "        могут быть идентифицированы как отдельные сущности, но на самом деле\n",
        "        это одна сущность \"Нью-Йорк\".\n",
        "\n",
        "        Параметры:\n",
        "            ner_result (list): Список именованных сущностей, возвращаемых пайплайном NER.\n",
        "\n",
        "        Возвращает:\n",
        "            list: Объединенный список именованных сущностей.\n",
        "        \"\"\"\n",
        "        entities = []       # Инициализация списка для объединенных сущностей\n",
        "        prev_entity = None  # Предыдущий тип сущности\n",
        "        prev_end = 0        # Позиция окончания предыдущей сущности\n",
        "\n",
        "        # Перебор результатов NER\n",
        "        for i in range(len(ner_result)):\n",
        "            # Проверка, является ли текущая сущность продолжением предыдущей\n",
        "            if (ner_result[i][\"entity_group\"] == prev_entity) and (ner_result[i][\"start\"] == prev_end):\n",
        "                # Обновление конечной позиции предыдущей сущности, объединяя ее с текущей\n",
        "                entities[-1][2] = ner_result[i][\"end\"]\n",
        "            else:\n",
        "                # Добавление новой сущности в список\n",
        "                entities.append([ner_result[i][\"entity_group\"],\n",
        "                                 ner_result[i][\"start\"],\n",
        "                                 ner_result[i][\"end\"]])\n",
        "            # Обновление информации о предыдущей сущности\n",
        "            prev_entity = ner_result[i][\"entity_group\"]\n",
        "            prev_end = ner_result[i][\"end\"]\n",
        "\n",
        "        return entities\n",
        "\n",
        "\n",
        "    def get_entities(self, text: str):\n",
        "        \"\"\"\n",
        "        Извлекает именованные сущности из текста.\n",
        "\n",
        "        Эта функция использует предварительно обученный NER пайплайн для определения\n",
        "        и извлечения именованных сущностей (например, имен, организаций, местоположений)\n",
        "        из предоставленного текста.\n",
        "\n",
        "        Параметры:\n",
        "            text (str): Текст для извлечения сущностей.\n",
        "\n",
        "        Возвращает:\n",
        "            list: Список извлеченных сущностей.\n",
        "\n",
        "        Ошибки:\n",
        "            AssertionError: Если текст пустой.\n",
        "        \"\"\"\n",
        "        # Проверка, что текст не пустой\n",
        "        assert len(text) > 0, \"Предоставленный текст пустой.\"\n",
        "\n",
        "        # Использование NER пайплайна для извлечения сущностей из текста\n",
        "        entities = self.token_pred_pipeline(text)\n",
        "\n",
        "        # Объединение соседних именованных сущностей одного типа\n",
        "        # Это полезно, когда одна сущность разбивается на несколько частей моделью NER\n",
        "        concat_ent = self.concat_entities(entities)\n",
        "\n",
        "        return concat_ent"
      ]
    }
  ]
}